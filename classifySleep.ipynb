{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import widgets\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search for csv location\n",
    "\n",
    "found = []\n",
    "\n",
    "def find(name,path):\n",
    "    path = os.getcwd() + path\n",
    "    file = name\n",
    "\n",
    "    for root, dir, files in os.walk(path):\n",
    "        for item in files:\n",
    "            if file == item:\n",
    "                return os.path.join(root, file)\n",
    "        return None\n",
    "data = ['00', '01', '02', '03', '05', '22', '23', '24', '25']\n",
    "for d in data:\n",
    "    found.append(find('data_' + d + '.csv.gz', '/irc-sphere-sleep-56db93f64661/sphere-sensor-data'))\n",
    "    found.append(find('data_' + d + '.csv', '/irc-sphere-sleep-56db93f64661/sphere-sensor-data'))\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load file\n",
    "\n",
    "df = []\n",
    "for path in found:\n",
    "    if path is not None:\n",
    "        if 'gz' in path:\n",
    "            fileName = path\n",
    "            df.append(pd.read_csv(fileName, index_col='datetime', compression='gzip'))\n",
    "        else: \n",
    "            fileName = path\n",
    "            df.append(pd.read_csv(fileName, index_col='datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatures(df):\n",
    "\n",
    "    # arm angle calculation using accelerometer data\n",
    "    df['angle'] = 180 / np.pi * np.arctan(df['wearable-xl1-z'] / np.sqrt(np.square(df['wearable-xl1-x']) + np.square(df['wearable-xl1-z'])))\n",
    "\n",
    "    # get only interesting columns\n",
    "    df = df[['angle', 'wearable-mag-xl1']]\n",
    "\n",
    "    # remove NaN values\n",
    "    df = df.dropna()\n",
    "    # convert index to DatetimeIndex\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "\n",
    "\n",
    "    # resample data within interval given in resampleInterval ('1S' = 1 second intervals)\n",
    "    resampleInterval = '1S'\n",
    "    minimum = df.resample(resampleInterval).min()\n",
    "    maximum = df.resample(resampleInterval).max()\n",
    "    mean = df.resample(resampleInterval).mean()\n",
    "    std = df.resample(resampleInterval).std()\n",
    "    summ = df.resample(resampleInterval).sum()\n",
    "    skew = df.resample(resampleInterval).apply(lambda array : stats.skew(array))\n",
    "    kurtosis = df.resample(resampleInterval).apply(lambda array: stats.kurtosis(array, fisher=True))\n",
    "\n",
    "    # rename column labels in DataFrame\n",
    "    minimum.rename(columns={'angle': 'angle min'}, inplace=True)\n",
    "    minimum.rename(columns={'wearable-mag-xl1': 'magnitude min'}, inplace=True)\n",
    "    \n",
    "    maximum.rename(columns={'angle': 'angle max'}, inplace=True)\n",
    "    maximum.rename(columns={'wearable-mag-xl1': 'magnitude max'}, inplace=True)\n",
    "    \n",
    "    mean.rename(columns={'angle': 'angle mean'}, inplace=True)\n",
    "    mean.rename(columns={'wearable-mag-xl1': 'magnitude mean'}, inplace=True)\n",
    "    \n",
    "    std.rename(columns={'angle': 'angle std'}, inplace=True)\n",
    "    std.rename(columns={'wearable-mag-xl1': 'magnutude std'}, inplace=True)\n",
    "    \n",
    "    summ.rename(columns={'angle': 'angle sum'}, inplace=True)\n",
    "    summ.rename(columns={'wearable-mag-xl1': 'magnitude sum'}, inplace=True)\n",
    "    \n",
    "    skew.rename(columns={'angle': 'angle skew'}, inplace=True)\n",
    "    skew.rename(columns={'wearable-mag-xl1': 'magnitude skew'}, inplace=True)\n",
    "    \n",
    "    kurtosis.rename(columns={'angle': 'angle kurtosis'}, inplace=True)\n",
    "    kurtosis.rename(columns={'wearable-mag-xl1': 'magnitude kurtosis'}, inplace=True)\n",
    "    \n",
    "    # collect DataFrames\n",
    "    features = [minimum, maximum, mean, std, summ, skew, kurtosis]\n",
    "    features = pd.concat(features, axis=1)\n",
    "\n",
    "    \n",
    "    # for some weird reason new nans appear. \n",
    "    # need to drop them to have same shape on what to plot\n",
    "    features = features.dropna()\n",
    "    std = std.dropna()\n",
    "    \n",
    "    return [features, std, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load features from data over all nights\n",
    "allFeatures = []\n",
    "allStd = []\n",
    "for d in df:\n",
    "    [feature, std, dataf] = getFeatures(d)\n",
    "    allFeatures.append(feature)\n",
    "    allStd.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalise the values between a 0 1 range\n",
    "normalisedFeatures = []\n",
    "for features in allFeatures:\n",
    "    features_array = features.values #return a numpy array\n",
    "    min_max_scalar = preprocessing.MinMaxScaler()\n",
    "    normalise = min_max_scalar.fit_transform(features_array)\n",
    "    normalised_features = pd.DataFrame(normalise)\n",
    "\n",
    "    # rename index and columns\n",
    "    normalised_features.columns = features.columns\n",
    "    normalised_features.index = features.index\n",
    "\n",
    "    features = normalised_features.copy(deep=True)\n",
    "    normalisedFeatures.append(features)\n",
    "normalisedFeatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(normalisedFeatures, open('allFeatures.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save all data to pkl\n",
    "data = pd.concat(normalisedFeatures, axis=0)\n",
    "data.to_pickle('normalisedDays.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can start from here to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-17aaa7bb0864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load pickled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normalisedDays.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalisedFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allFeatures.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "# load pickled data\n",
    "data = pd.read_pickle('normalisedDays.pkl')\n",
    "normalisedFeatures = pickle.load('allFeatures.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster data\n",
    "label = KMeans(n_clusters=5, random_state=10).fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot PCA of clusters\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(data)\n",
    "X = pca.transform(data)\n",
    "\n",
    "# only needed for non int labels (I think)\n",
    "# y = np.choose(label, [1, 2, 0]).astype(np.float)\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=label, cmap=plt.cm.spectral) # alt. cmap='spring'\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter of labelled data\n",
    "plt.scatter(data.index, data['angle std'], c=label)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and export features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model to data\n",
    "trainModel = KMeans(n_clusters=5, random_state=10).fit(data)\n",
    "\n",
    "# this is the model that should be used to predict sleep/not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: drop doesnt work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect features for the sleep data of each day\n",
    "sleepFeatures = []\n",
    "for feature in normalisedFeatures:\n",
    "    label = trainModel.predict(feature)\n",
    "    \n",
    "    # merge clusters\n",
    "    label[label == 0] = 0\n",
    "    label[label == 1] = 0\n",
    "    label[label == 2] = 0\n",
    "    label[label == 3] = 0\n",
    "    label[label == 4] = 1\n",
    "    \n",
    "    # drop awake data\n",
    "    for i,n in enumerate(label):\n",
    "        if(n == 1):\n",
    "            feature.drop(feature.index[i])\n",
    "    feat = np.concatenate((feature.mean(), feature.std(), feature.skew(), feature.kurt()), axis=0)\n",
    "    sleepFeatures.append(feat)\n",
    "    \n",
    "    normalisedFeatures['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export sleep features\n",
    "sleepFeatures=np.asarray(sleepFeatures)\n",
    "np.save('sleepFeatures.npy', sleepFeatures, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: map label to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
